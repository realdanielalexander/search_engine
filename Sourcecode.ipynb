{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import ast\n",
    "from itertools import islice\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Download Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load File</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "try:\n",
    "    filename = os.listdir('Data')[115]\n",
    "    f = open('Data/' + filename, 'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Case Folding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<date> 9-mar-1987 05:03:09.75</date>\n",
      "<title>bank of france sets money market tender</title>\n",
      "<body>the bank of france said it invited offers\n",
      "of first category paper today for a money market intervention\n",
      "tender.\n",
      "    money market dealers said conditions seemed right for the\n",
      "bank to cut its intervention rate at the tender by a quarter\n",
      "percentage point to 7-3/4 pct from eight, reflecting an easing\n",
      "in call money rate last week, and the french franc's steadiness\n",
      "on foreign exchange markets since the february 22 currency\n",
      "stabilisation accord here by the group of five and canada.\n",
      "    intervention rate was last raised to eight pct from 7-1/4\n",
      "on january 2. call money today was quoted at 7-11/16 7-3/4 pct.\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " 'date',\n",
       " '>',\n",
       " '9-mar-1987',\n",
       " '05:03:09.75',\n",
       " '<',\n",
       " '/date',\n",
       " '>',\n",
       " '<',\n",
       " 'title',\n",
       " '>',\n",
       " 'bank',\n",
       " 'of',\n",
       " 'france',\n",
       " 'sets',\n",
       " 'money',\n",
       " 'market',\n",
       " 'tender',\n",
       " '<',\n",
       " '/title',\n",
       " '>',\n",
       " '<',\n",
       " 'body',\n",
       " '>',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'of',\n",
       " 'france',\n",
       " 'said',\n",
       " 'it',\n",
       " 'invited',\n",
       " 'offers',\n",
       " 'of',\n",
       " 'first',\n",
       " 'category',\n",
       " 'paper',\n",
       " 'today',\n",
       " 'for',\n",
       " 'a',\n",
       " 'money',\n",
       " 'market',\n",
       " 'intervention',\n",
       " 'tender',\n",
       " '.',\n",
       " 'money',\n",
       " 'market',\n",
       " 'dealers',\n",
       " 'said',\n",
       " 'conditions',\n",
       " 'seemed',\n",
       " 'right',\n",
       " 'for',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'to',\n",
       " 'cut',\n",
       " 'its',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'at',\n",
       " 'the',\n",
       " 'tender',\n",
       " 'by',\n",
       " 'a',\n",
       " 'quarter',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'to',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " 'from',\n",
       " 'eight',\n",
       " ',',\n",
       " 'reflecting',\n",
       " 'an',\n",
       " 'easing',\n",
       " 'in',\n",
       " 'call',\n",
       " 'money',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'week',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'french',\n",
       " 'franc',\n",
       " \"'s\",\n",
       " 'steadiness',\n",
       " 'on',\n",
       " 'foreign',\n",
       " 'exchange',\n",
       " 'markets',\n",
       " 'since',\n",
       " 'the',\n",
       " 'february',\n",
       " '22',\n",
       " 'currency',\n",
       " 'stabilisation',\n",
       " 'accord',\n",
       " 'here',\n",
       " 'by',\n",
       " 'the',\n",
       " 'group',\n",
       " 'of',\n",
       " 'five',\n",
       " 'and',\n",
       " 'canada',\n",
       " '.',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'was',\n",
       " 'last',\n",
       " 'raised',\n",
       " 'to',\n",
       " 'eight',\n",
       " 'pct',\n",
       " 'from',\n",
       " '7-1/4',\n",
       " 'on',\n",
       " 'january',\n",
       " '2.',\n",
       " 'call',\n",
       " 'money',\n",
       " 'today',\n",
       " 'was',\n",
       " 'quoted',\n",
       " 'at',\n",
       " '7-11/16',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " '.',\n",
       " '<',\n",
       " '/body',\n",
       " '>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tokenisasi String + Regex</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "['<date>', '9 mar 1987', '05:03:09.75', '</date>', '<title>', 'bank', 'of', 'france', 'sets', 'money', 'market', 'tender', '</title>', '<body>', 'the', 'bank', 'of', 'france', 'said', 'it', 'invited', 'offers', 'of', 'first', 'category', 'paper', 'today', 'for', 'a', 'money', 'market', 'intervention', 'tender', 'money', 'market', 'dealers', 'said', 'conditions', 'seemed', 'right', 'for', 'the', 'bank', 'to', 'cut', 'its', 'intervention', 'rate', 'at', 'the', 'tender', 'by', 'a', 'quarter', 'percentage', 'point', 'to', '7 3/4', 'pct', 'from', 'eight', 'reflecting', 'an', 'easing', 'in', 'call', 'money', 'rate', 'last', 'week', 'and', 'the', 'french', 'franc', 'steadiness', 'on', 'foreign', 'exchange', 'markets', 'since', 'the', 'february', '22', 'currency', 'stabilisation', 'accord', 'here', 'by', 'the', 'group', 'of', 'five', 'and', 'canada', 'intervention', 'rate', 'was', 'last', 'raised', 'to', 'eight', 'pct', 'from', '7 1/4', 'on', 'january', '2', 'call', 'money', 'today', 'was', 'quoted', 'at', '7 11/16', '7 3/4', 'pct', '</body>']\n"
     ]
    }
   ],
   "source": [
    "# testing = \"Harga mangga per kg adalah 20.500.\"\n",
    "tokens = word_tokenize(text)\n",
    "# print(tokens[:5])\n",
    "# print(' '.join(tokens))\n",
    "check = ''\n",
    "save = ''\n",
    "def join_tags(tokens):\n",
    "    for i in enumerate(tokens):\n",
    "        hit = 0\n",
    "        index = i[0]\n",
    "        y = i[1]\n",
    "        width = len(y)\n",
    "        \n",
    "        for x in y:\n",
    "            if x is '-':\n",
    "                #save = tokens[index][hit+1:]\n",
    "                #tokens[index] = tokens[index][0:hit] + ''\n",
    "                #tokens[index+1] = save\n",
    "                #print(save)\n",
    "                #print(tokens[index])\n",
    "                tokens[index] = tokens[index][0:hit] + ' ' + tokens[index][hit+1:]\n",
    "            hit += 1\n",
    "        \n",
    "        if tokens[index] is ' ':\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if tokens[index] == '  ':\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if y[(width-1):width] is '.':\n",
    "            tokens[index] = y[0:(width-1)]\n",
    "        \n",
    "        if tokens[index][0:1] is '-' or tokens[index][1:2] is '-':\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if tokens[index][-2:-1] is \"'\":\n",
    "            tokens[index] = tokens[index][0:-2]\n",
    "        \n",
    "        if  tokens[index][:1] is \"'\" :\n",
    "            tokens[index] = tokens[index][1:]\n",
    "        \n",
    "        if tokens[index] is \"s\" or tokens[index] is \"re\":\n",
    "            tokens[index-1] = tokens[index-1]\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if tokens[index] is '<' and tokens[index+2] is '>':\n",
    "            tokens[index+2] = '<'+ tokens[index+1]+'>'\n",
    "            tokens[index] =''\n",
    "            tokens[index+1] = ''\n",
    "            \n",
    "        if tokens[index] is '&' and tokens[index+2] is ';':\n",
    "            tokens[index+2] = ''\n",
    "            tokens[index] = ''\n",
    "            tokens[index+1] = ''\n",
    "            \n",
    "        if tokens[index] is '(' or tokens[index] is ')':\n",
    "            tokens[index] = ''\n",
    "            \n",
    "        if tokens[index][0:1] is ':':\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if tokens[index][0:1] is '.' and tokens[index][1:2] is '.':\n",
    "            tokens[index] = ''\n",
    "\n",
    "        if y[(width-2):(width-1)] == '.' and y[(width-1):(width)] == '0':\n",
    "            tokens[index] = y[0:(width-2)]\n",
    "        \n",
    "    tokens_clean = [x for x in tokens if x != '' and x not in \".,!?'\" and x not in '<>']\n",
    "        \n",
    "    return tokens_clean\n",
    "\n",
    "tokens_clean = join_tags(tokens)\n",
    "print(len(tokens_clean))\n",
    "print(tokens_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stop Words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<date>', '9 mar 1987', '05:03:09.75', '</date>', '<title>', 'bank', 'france', 'sets', 'money', 'market', 'tender', '</title>', '<body>', 'bank', 'france', 'said', 'invited', 'offers', 'first', 'category', 'paper', 'today', 'money', 'market', 'intervention', 'tender', 'money', 'market', 'dealers', 'said', 'conditions', 'seemed', 'right', 'bank', 'cut', 'intervention', 'rate', 'tender', 'quarter', 'percentage', 'point', '7 3/4', 'pct', 'eight', 'reflecting', 'easing', 'call', 'money', 'rate', 'last', 'week', 'french', 'franc', 'steadiness', 'foreign', 'exchange', 'markets', 'since', 'february', '22', 'currency', 'stabilisation', 'accord', 'group', 'five', 'canada', 'intervention', 'rate', 'last', 'raised', 'eight', 'pct', '7 1/4', 'january', '2', 'call', 'money', 'today', 'quoted', '7 11/16', '7 3/4', 'pct', '</body>']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [w for w in tokens_clean if not w in stop_words]\n",
    "print(filtered_words[:len(filtered_words)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stemming</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<date>', '9 mar 1987', '05:03:09.75', '</date>', '<title>', 'bank', 'franc', 'set', 'money', 'market', 'tender', '</title>', '<body>', 'bank', 'franc', 'said', 'invit', 'offer', 'first', 'categori', 'paper', 'today', 'money', 'market', 'intervent', 'tender', 'money', 'market', 'dealer', 'said', 'condit', 'seem', 'right', 'bank', 'cut', 'intervent', 'rate', 'tender', 'quarter', 'percentag', 'point', '7 3/4', 'pct', 'eight', 'reflect', 'eas', 'call', 'money', 'rate', 'last', 'week', 'french', 'franc', 'steadi', 'foreign', 'exchang', 'market', 'sinc', 'februari', '22', 'currenc', 'stabilis', 'accord', 'group', 'five', 'canada', 'intervent', 'rate', 'last', 'rais', 'eight', 'pct', '7 1/4', 'januari', '2', 'call', 'money', 'today', 'quot', '7 11/16', '7 3/4', 'pct', '</body>']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lemmatizing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam proses lematisasi, fungsi lemmatize pada NLTK membutuhkan tambahan parameter berupa POS (Part of Speech), yaitu konteks jenis kata, apakah kata berupa adjective, noun, verb, atau adverb. Maka dari itu, perlu dibuat suatu fungsi yang dapat mengembalikan objek POS dari library WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<date>',\n",
       " '9 mar 1987',\n",
       " '05:03:09.75',\n",
       " '</date>',\n",
       " '<title>',\n",
       " 'bank',\n",
       " 'france',\n",
       " 'set',\n",
       " 'money',\n",
       " 'market',\n",
       " 'tender',\n",
       " '</title>',\n",
       " '<body>',\n",
       " 'bank',\n",
       " 'france',\n",
       " 'say',\n",
       " 'invite',\n",
       " 'offer',\n",
       " 'first',\n",
       " 'category',\n",
       " 'paper',\n",
       " 'today',\n",
       " 'money',\n",
       " 'market',\n",
       " 'intervention',\n",
       " 'tender',\n",
       " 'money',\n",
       " 'market',\n",
       " 'dealer',\n",
       " 'say',\n",
       " 'condition',\n",
       " 'seem',\n",
       " 'right',\n",
       " 'bank',\n",
       " 'cut',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'tender',\n",
       " 'quarter',\n",
       " 'percentage',\n",
       " 'point',\n",
       " '7 3/4',\n",
       " 'pct',\n",
       " 'eight',\n",
       " 'reflect',\n",
       " 'ease',\n",
       " 'call',\n",
       " 'money',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'week',\n",
       " 'french',\n",
       " 'franc',\n",
       " 'steadiness',\n",
       " 'foreign',\n",
       " 'exchange',\n",
       " 'market',\n",
       " 'since',\n",
       " 'february',\n",
       " '22',\n",
       " 'currency',\n",
       " 'stabilisation',\n",
       " 'accord',\n",
       " 'group',\n",
       " 'five',\n",
       " 'canada',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'raise',\n",
       " 'eight',\n",
       " 'pct',\n",
       " '7 1/4',\n",
       " 'january',\n",
       " '2',\n",
       " 'call',\n",
       " 'money',\n",
       " 'today',\n",
       " 'quote',\n",
       " '7 11/16',\n",
       " '7 3/4',\n",
       " 'pct',\n",
       " '</body>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = list()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in filtered_words]\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stemming and Lemmatization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<date>',\n",
       " '9 mar 1987',\n",
       " '05:03:09.75',\n",
       " '</date>',\n",
       " '<title>',\n",
       " 'bank',\n",
       " 'franc',\n",
       " 'set',\n",
       " 'money',\n",
       " 'market',\n",
       " 'tender',\n",
       " '</title>',\n",
       " '<body>',\n",
       " 'bank',\n",
       " 'franc',\n",
       " 'say',\n",
       " 'invit',\n",
       " 'offer',\n",
       " 'first',\n",
       " 'categori',\n",
       " 'paper',\n",
       " 'today',\n",
       " 'money',\n",
       " 'market',\n",
       " 'intervent',\n",
       " 'tender',\n",
       " 'money',\n",
       " 'market',\n",
       " 'dealer',\n",
       " 'say',\n",
       " 'condit',\n",
       " 'seem',\n",
       " 'right',\n",
       " 'bank',\n",
       " 'cut',\n",
       " 'intervent',\n",
       " 'rate',\n",
       " 'tender',\n",
       " 'quarter',\n",
       " 'percentag',\n",
       " 'point',\n",
       " '7 3/4',\n",
       " 'pct',\n",
       " 'eight',\n",
       " 'reflect',\n",
       " 'ea',\n",
       " 'call',\n",
       " 'money',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'week',\n",
       " 'french',\n",
       " 'franc',\n",
       " 'steadi',\n",
       " 'foreign',\n",
       " 'exchang',\n",
       " 'market',\n",
       " 'sinc',\n",
       " 'februari',\n",
       " '22',\n",
       " 'currenc',\n",
       " 'stabilis',\n",
       " 'accord',\n",
       " 'group',\n",
       " 'five',\n",
       " 'canada',\n",
       " 'intervent',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'rais',\n",
       " 'eight',\n",
       " 'pct',\n",
       " '7 1/4',\n",
       " 'januari',\n",
       " '2',\n",
       " 'call',\n",
       " 'money',\n",
       " 'today',\n",
       " 'quot',\n",
       " '7 11/16',\n",
       " '7 3/4',\n",
       " 'pct',\n",
       " '</body>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in stemmed_words]\n",
    "stemmed_lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabel Perbandingan Token</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di bawah ini ditampilkan tabel perbandingan dari token sebelum dan sesudah dilakukan dua pendekatan, yaitu stemming dan lematisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered</th>\n",
       "      <th>Stemmed</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Stemmed and Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9 mar 1987</td>\n",
       "      <td>9 mar 1987</td>\n",
       "      <td>9 mar 1987</td>\n",
       "      <td>9 mar 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>05:03:09.75</td>\n",
       "      <td>05:03:09.75</td>\n",
       "      <td>05:03:09.75</td>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>quoted</td>\n",
       "      <td>quot</td>\n",
       "      <td>quote</td>\n",
       "      <td>quot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>7 11/16</td>\n",
       "      <td>7 11/16</td>\n",
       "      <td>7 11/16</td>\n",
       "      <td>7 11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>7 3/4</td>\n",
       "      <td>7 3/4</td>\n",
       "      <td>7 3/4</td>\n",
       "      <td>7 3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filtered      Stemmed   Lemmatized Stemmed and Lemmatized\n",
       "0        <date>       <date>       <date>                 <date>\n",
       "1    9 mar 1987   9 mar 1987   9 mar 1987             9 mar 1987\n",
       "2   05:03:09.75  05:03:09.75  05:03:09.75            05:03:09.75\n",
       "3       </date>      </date>      </date>                </date>\n",
       "4       <title>      <title>      <title>                <title>\n",
       "..          ...          ...          ...                    ...\n",
       "78       quoted         quot        quote                   quot\n",
       "79      7 11/16      7 11/16      7 11/16                7 11/16\n",
       "80        7 3/4        7 3/4        7 3/4                  7 3/4\n",
       "81          pct          pct          pct                    pct\n",
       "82      </body>      </body>      </body>                </body>\n",
       "\n",
       "[83 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "df_raw['Token'] = tokens_clean\n",
    "df['Filtered'] = filtered_words\n",
    "df['Stemmed'] = stemmed_words\n",
    "df['Lemmatized'] = lemmatized_words\n",
    "df['Stemmed and Lemmatized'] = stemmed_lemmatized_words\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabel Perbandingan Term</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term adalah token yang unik, di mana setiap term hanya muncul satu kali. Kami menggunakan fungsi set() untuk membuat setiap kata muncul hanya satu kali. Berbeda dengan token yang dapat muncul beberapa kali, term menggabungkan beberapa kata dasar dengan infleksi yang berbeda, sehingga tidak dapat ditampilkan secara side-by-side karena jumlahnya tidak sesuai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_set = list(set(tokens_clean))\n",
    "\n",
    "aa = filtered_words\n",
    "aaa = stemmed_words\n",
    "aaaa = lemmatized_words\n",
    "filtered_set = sorted(list(set(filtered_words)))\n",
    "stemmed_set = sorted(list(set(stemmed_words)))\n",
    "lemmatized_set = sorted(list(set(lemmatized_words)))\n",
    "\n",
    "df_filtered_set = pd.DataFrame(filtered_set,columns=['Filtered'])\n",
    "df_stemmed_set = pd.DataFrame(stemmed_set,columns=['Stemmed'])\n",
    "df_lemmatized_set = pd.DataFrame(lemmatized_set,columns=['Lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7 1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7 11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7 3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9 mar 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>dealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>easing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>invited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>offers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>quoted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>raised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>reflecting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>seemed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>stabilisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>steadiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filtered\n",
       "0     05:03:09.75\n",
       "1               2\n",
       "2              22\n",
       "3           7 1/4\n",
       "4         7 11/16\n",
       "5           7 3/4\n",
       "6      9 mar 1987\n",
       "7         </body>\n",
       "8         </date>\n",
       "9        </title>\n",
       "10         <body>\n",
       "11         <date>\n",
       "12        <title>\n",
       "13         accord\n",
       "14           bank\n",
       "15           call\n",
       "16         canada\n",
       "17       category\n",
       "18     conditions\n",
       "19       currency\n",
       "20            cut\n",
       "21        dealers\n",
       "22         easing\n",
       "23          eight\n",
       "24       exchange\n",
       "25       february\n",
       "26          first\n",
       "27           five\n",
       "28        foreign\n",
       "29          franc\n",
       "30         france\n",
       "31         french\n",
       "32          group\n",
       "33   intervention\n",
       "34        invited\n",
       "35        january\n",
       "36           last\n",
       "37         market\n",
       "38        markets\n",
       "39          money\n",
       "40         offers\n",
       "41          paper\n",
       "42            pct\n",
       "43     percentage\n",
       "44          point\n",
       "45        quarter\n",
       "46         quoted\n",
       "47         raised\n",
       "48           rate\n",
       "49     reflecting\n",
       "50          right\n",
       "51           said\n",
       "52         seemed\n",
       "53           sets\n",
       "54          since\n",
       "55  stabilisation\n",
       "56     steadiness\n",
       "57         tender\n",
       "58          today\n",
       "59           week"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7 1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7 11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7 3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9 mar 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>categori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>condit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>currenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>dealer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>eas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>exchang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>februari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>intervent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>invit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>percentag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>quot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>rais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>reflect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>seem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>sinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>stabilis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>steadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Stemmed\n",
       "0   05:03:09.75\n",
       "1             2\n",
       "2            22\n",
       "3         7 1/4\n",
       "4       7 11/16\n",
       "5         7 3/4\n",
       "6    9 mar 1987\n",
       "7       </body>\n",
       "8       </date>\n",
       "9      </title>\n",
       "10       <body>\n",
       "11       <date>\n",
       "12      <title>\n",
       "13       accord\n",
       "14         bank\n",
       "15         call\n",
       "16       canada\n",
       "17     categori\n",
       "18       condit\n",
       "19      currenc\n",
       "20          cut\n",
       "21       dealer\n",
       "22          eas\n",
       "23        eight\n",
       "24      exchang\n",
       "25     februari\n",
       "26        first\n",
       "27         five\n",
       "28      foreign\n",
       "29        franc\n",
       "30       french\n",
       "31        group\n",
       "32    intervent\n",
       "33        invit\n",
       "34      januari\n",
       "35         last\n",
       "36       market\n",
       "37        money\n",
       "38        offer\n",
       "39        paper\n",
       "40          pct\n",
       "41    percentag\n",
       "42        point\n",
       "43      quarter\n",
       "44         quot\n",
       "45         rais\n",
       "46         rate\n",
       "47      reflect\n",
       "48        right\n",
       "49         said\n",
       "50         seem\n",
       "51          set\n",
       "52         sinc\n",
       "53     stabilis\n",
       "54       steadi\n",
       "55       tender\n",
       "56        today\n",
       "57         week"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stemmed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7 1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7 11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7 3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9 mar 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>dealer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>ease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>invite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>quote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>reflect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>seem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>stabilisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>steadiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lemmatized\n",
       "0     05:03:09.75\n",
       "1               2\n",
       "2              22\n",
       "3           7 1/4\n",
       "4         7 11/16\n",
       "5           7 3/4\n",
       "6      9 mar 1987\n",
       "7         </body>\n",
       "8         </date>\n",
       "9        </title>\n",
       "10         <body>\n",
       "11         <date>\n",
       "12        <title>\n",
       "13         accord\n",
       "14           bank\n",
       "15           call\n",
       "16         canada\n",
       "17       category\n",
       "18      condition\n",
       "19       currency\n",
       "20            cut\n",
       "21         dealer\n",
       "22           ease\n",
       "23          eight\n",
       "24       exchange\n",
       "25       february\n",
       "26          first\n",
       "27           five\n",
       "28        foreign\n",
       "29          franc\n",
       "30         france\n",
       "31         french\n",
       "32          group\n",
       "33   intervention\n",
       "34         invite\n",
       "35        january\n",
       "36           last\n",
       "37         market\n",
       "38          money\n",
       "39          offer\n",
       "40          paper\n",
       "41            pct\n",
       "42     percentage\n",
       "43          point\n",
       "44        quarter\n",
       "45          quote\n",
       "46          raise\n",
       "47           rate\n",
       "48        reflect\n",
       "49          right\n",
       "50            say\n",
       "51           seem\n",
       "52            set\n",
       "53          since\n",
       "54  stabilisation\n",
       "55     steadiness\n",
       "56         tender\n",
       "57          today\n",
       "58           week"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmatized_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Penggabungan token menjadi teks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teks diproses dengan Stemming</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<date> 9 mar 1987 05:03:09.75 </date> <title> bank franc set money market tender </title> <body> bank franc said invit offer first categori paper today money market intervent tender money market dealer said condit seem right bank cut intervent rate tender quarter percentag point 7 3/4 pct eight reflect eas call money rate last week french franc steadi foreign exchang market sinc februari 22 currenc stabilis accord group five canada intervent rate last rais eight pct 7 1/4 januari 2 call money today quot 7 11/16 7 3/4 pct </body>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_text = ' '.join(stemmed_words)\n",
    "stemmed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teks diproses dengan Lematisasi</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<date> 9 mar 1987 05:03:09.75 </date> <title> bank france set money market tender </title> <body> bank france say invite offer first category paper today money market intervention tender money market dealer say condition seem right bank cut intervention rate tender quarter percentage point 7 3/4 pct eight reflect ease call money rate last week french franc steadiness foreign exchange market since february 22 currency stabilisation accord group five canada intervention rate last raise eight pct 7 1/4 january 2 call money today quote 7 11/16 7 3/4 pct </body>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text = ' '.join(lemmatized_words)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mempermudah pekerjaan, kami membuat fungsi - fungsi di atas menjadi satu fungsi yaitu preprocess. Fungsi ini akan menerima parameter teks dan return teks dengan dua pendekatan, yaitu stemming dan lematisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_process):\n",
    "    text_process = text_process.lower()\n",
    "    tokens = word_tokenize(text_process)\n",
    "    tokens_clean = join_tags(tokens)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [w for w in tokens_clean if not w in stop_words]\n",
    "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in stemmed_words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    #clean_text = lemmatized_text\n",
    "    clean_text = lemmatized_text\n",
    "    clean_words = sorted(list([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in stemmed_words]))\n",
    "    clean_text = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root>' + clean_text + '</root>'\n",
    "    return clean_text, clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_term_doc = dict()\n",
    "clean_words_list = list()\n",
    "raw_words_list = list()\n",
    "dict_term_doc_final = dict()\n",
    "data = dict()\n",
    "key = list()\n",
    "value = list()\n",
    "\n",
    "for i in os.listdir('Data'):\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Data/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        clean_text, clean_words = preprocess(text)\n",
    "        clean_words_list.extend(clean_words)\n",
    "        for w in clean_words:\n",
    "            if w not in dict_term_doc:\n",
    "                dict_term_doc[w] = [filename[4:7]]\n",
    "            else:\n",
    "                dict_term_doc[w].append(filename[4:7])\n",
    "#         target = 'Clean/' + filename[:-3] +'xml'\n",
    "#         new_file = open(target, 'w+')\n",
    "#         new_file.write(clean_text)\n",
    "#         new_file.close()\n",
    "#     except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "for i in sorted(dict_term_doc.keys()):\n",
    "    dict_term_doc_final[i] = dict_term_doc[i]\n",
    "    \n",
    "df_term_doc = pd.DataFrame(dict_term_doc_final.items(), columns = ['Term', 'Documents'])\n",
    "\n",
    "df_term_doc.to_csv('Konstruksi Indeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_term_doc = dict()\n",
    "# clean_words_list = list()\n",
    "# raw_words_list = list()\n",
    "# dict_term_doc_final = dict()\n",
    "# data = dict()\n",
    "# key = list()\n",
    "# value = list()\n",
    "for i in os.listdir('Data'):\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Data/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        clean_text = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root>' + text + '</root>'\n",
    "        target = 'XML/' + filename[:-3] +'xml'\n",
    "        new_file = open(target, 'w+')\n",
    "        new_file.write(clean_text)\n",
    "        new_file.close()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "# for i in sorted(dict_term_doc.keys()):\n",
    "#     dict_term_doc_final[i] = dict_term_doc[i]\n",
    "    \n",
    "# df_term_doc = pd.DataFrame(dict_term_doc_final.items(), columns = ['Term', 'Documents'])\n",
    "\n",
    "# df_term_doc.to_csv('Konstruksi Indeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'standard oil north america'\n",
    "clean_query_text, clean_query_words = preprocess(query)\n",
    "clean_query_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>FUNGSI LANGUAGE MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "dict_term_doc = dict()\n",
    "clean_words_list = list()\n",
    "raw_words_list = list()\n",
    "dict_term_doc_final = dict()\n",
    "data = dict()\n",
    "key = list()\n",
    "value = list()\n",
    "doc_freqs = dict()\n",
    "\n",
    "query = '1991'\n",
    "clean_query_text, clean_query_words = preprocess(query)\n",
    "lambd = 1/4\n",
    "limit = 500\n",
    "result_dict = list()\n",
    "\n",
    "global_freq = 0\n",
    "start = timeit.default_timer()\n",
    "for index, i in enumerate(os.listdir('Data')):\n",
    "    print(index)\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Data/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        clean_text, clean_words = preprocess(text)\n",
    "        clean_words_list.extend(clean_words)\n",
    "        \n",
    "#         print(clean_words)\n",
    "        doc_freq = 0\n",
    "        for w in clean_words:\n",
    "            doc_freq+=1\n",
    "            doc_freqs[filename[4:7]] = doc_freq\n",
    "            if w not in dict_term_doc:\n",
    "                dict_term_doc[w] = [1, {filename[4:7]: 1}]\n",
    "            else:\n",
    "                if filename[4:7] in dict_term_doc[w][1]:\n",
    "                    dict_term_doc[w][1][filename[4:7]]+=1\n",
    "                else:\n",
    "                    dict_term_doc[w][1][filename[4:7]]=1\n",
    "                dict_term_doc[w][0]+=1\n",
    "        if index == limit:\n",
    "            break\n",
    "#         target = 'Clean/' + filename[:-3] +'xml'\n",
    "#         new_file = open(target, 'w+')\n",
    "#         new_file.write(clean_text)\n",
    "#         new_file.close()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "print(doc_freqs)\n",
    "df_doc_freqs = pd.DataFrame(doc_freqs.items(), columns = ['Document', 'Frequency'])\n",
    "df_doc_freqs.to_csv('Document Frequencies.csv')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Waktu pembuatan indeks:\", stop-start)\n",
    "start = timeit.default_timer()\n",
    "for i in sorted(dict_term_doc.keys()):\n",
    "    dict_term_doc_final[i] = dict_term_doc[i]\n",
    "\n",
    "\n",
    "    \n",
    "df_term_doc = pd.DataFrame(dict_term_doc_final.items(), columns = ['Term', 'Documents'])\n",
    "\n",
    "df_term_doc.to_csv('Frequencies.csv')\n",
    "\n",
    "df = pd.read_csv('Frequencies.csv')\n",
    "df_doc_freq = pd.read_csv('Document Frequencies.csv')\n",
    "\n",
    "global_freq = 0\n",
    "for i in islice(df.iterrows(), limit):\n",
    "    documents = i[1][2].strip('][').replace(\"'\", \"\").split(', ')\n",
    "    try:\n",
    "        global_freq+=int(documents[0])\n",
    "    except:\n",
    "        print('noo')\n",
    "\n",
    "for i in islice(df_doc_freq.iterrows(), limit):\n",
    "    local_freq = i[1]['Frequency']\n",
    "    doc_number = i[1]['Document']\n",
    "    doc_number = str(doc_number).zfill(3)\n",
    "    result = 1\n",
    "    for j in query.split():\n",
    "        entries = df.loc[df['Term'] == j]['Documents'].values[0]\n",
    "        entries = entries.split(', ',1)\n",
    "        entries[0] = entries[0].replace(\"[\", \"\")\n",
    "        entries[1] = entries[1].replace(']', '')\n",
    "        entries[1] = ast.literal_eval(entries[1])\n",
    "        if doc_number in entries[1].keys():\n",
    "            prob = (float(entries[1][doc_number])/float(local_freq)*lambd) + (float(entries[0])/float(global_freq)*(1-lambd))\n",
    "        else:\n",
    "            prob = (float(entries[0])/float(global_freq)*(1-lambd))\n",
    "        result *= prob\n",
    "    result_dict.append((doc_number, result))\n",
    "result_sorted = sorted(result_dict, key=lambda x: x[1], reverse=True)\n",
    "print(result_sorted)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Waktu pembuatan indeks:\", stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Frequencies.csv')\n",
    "global_freq = 0\n",
    "for i in df.iterrows():\n",
    "    documents = i[1][2].strip('][').replace(\"'\", \"\").split(', ')\n",
    "    try:\n",
    "        global_freq+=int(documents[0])\n",
    "    except:\n",
    "        print('noo')\n",
    "text_file = open(\"global_frequency.txt\", \"w\")\n",
    "text_file.write(str(global_freq))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50615\n",
      "[('031', 0.010550026342652046), ('190', 0.005341693009318713), ('301', 0.0038098302642206737), ('105', 0.0033801129227386266), ('070', 0.0027106792636142456)]\n",
      "Waktu pembuatan indeks: 0.9566341000008833\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "query = '1991'\n",
    "clean_query_text, clean_query_words = preprocess(query)\n",
    "lambd = 1/4\n",
    "limit = 5\n",
    "result_dict = list()\n",
    "\n",
    "df_doc_freq = pd.read_csv('Document Frequencies.csv')\n",
    "\n",
    "global_freq = int(open(\"global_frequency.txt\", \"r\").read())\n",
    "print(global_freq)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for i in df_doc_freq.iterrows():\n",
    "    local_freq = i[1]['Frequency']\n",
    "    doc_number = i[1]['Document']\n",
    "    doc_number = str(doc_number).zfill(3)\n",
    "    result = 1\n",
    "    for j in query.split():\n",
    "        entries = df.loc[df['Term'] == j]['Documents'].values[0]\n",
    "        entries = entries.split(', ',1)\n",
    "        entries[0] = entries[0].replace(\"[\", \"\")\n",
    "        entries[1] = entries[1].replace(']', '')\n",
    "        entries[1] = ast.literal_eval(entries[1])\n",
    "        if doc_number in entries[1].keys():\n",
    "            prob = (float(entries[1][doc_number])/float(local_freq)*lambd) + (float(entries[0])/float(global_freq)*(1-lambd))\n",
    "        else:\n",
    "            prob = (float(entries[0])/float(global_freq)*(1-lambd))\n",
    "        result *= prob\n",
    "    result_dict.append((doc_number, result))\n",
    "result_sorted = sorted(result_dict, key=lambda x: x[1], reverse=True)\n",
    "print(result_sorted[:limit])\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Waktu pembuatan indeks:\", stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(doc_freqs)\n",
    "df_doc_freqs = pd.DataFrame(doc_freqs.items(), columns = ['Document', 'Frequency'])\n",
    "df_doc_freqs.to_csv('Document Frequencies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_freqs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> TF-IDF </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Frequency Words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = dict()\n",
    "key_words = []\n",
    "\n",
    "for i in os.listdir('Clean'):\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Clean/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        words = text.split()\n",
    "        for w in words: \n",
    "            freq_dict[w] = freq_dict.get(w,0) + 1\n",
    "            key_words.append(freq_dict)\n",
    "        print(freq_dict)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# def words_frequency(text):\n",
    "#     freq_dict = dict()\n",
    "#     print(text)\n",
    "#     for wrd in text:\n",
    "#         print (wrd)\n",
    "#         wds = wrd.split()\n",
    "#         for w in wds: \n",
    "#             freq_dict[w] = freq_dict.get(w,0) + 1\n",
    "#     return freq_dict\n",
    "\n",
    "# frequency_words = words_frequency(stemmed_lemmatized_words)\n",
    "# frequency_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_freq = pd.DataFrame()\n",
    "\n",
    "# df_freq['Words'] = freq_dict.keys()\n",
    "# df_freq['Total Frequency'] = freq_dict.values()\n",
    "\n",
    "# df_freq.to_csv(\"Frequency.csv\")\n",
    "\n",
    "# df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Frequency Document</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read_freq = pd.read_csv('Konstruksi Indeks.csv')\n",
    "\n",
    "df_out = df_read_freq['Documents']\n",
    "total_freq = []\n",
    "\n",
    "for i in df_read_freq.iterrows():\n",
    "    l_freq = dict()\n",
    "    res = i.strip('][').replace(\"'\", \"\").split(', ')\n",
    "    for j in res:\n",
    "        if j in l_freq:\n",
    "            l_freq[j]+=1\n",
    "        else:\n",
    "            l_freq[j] = 1\n",
    "    \n",
    "    total_freq.append(l_freq)\n",
    "print(total_freq)\n",
    "df_freq_total = pd.DataFrame()\n",
    "df_freq_total['Total'] = total_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Search</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(\"Konstruksi Indeks.csv\")\n",
    "df_read_copy = df_read\n",
    "df_read_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"\")\n",
    "user_input = user_input.lower()\n",
    "user_input = word_tokenize(user_input)\n",
    "user_input = join_tags(user_input)\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indent = list()\n",
    "for i in user_input:\n",
    "    indent.append(i)\n",
    "    \n",
    "print(indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "checker = True\n",
    "for i in indent:\n",
    "    save = ''\n",
    "    n = 0\n",
    "    y = 0\n",
    "    z = 1\n",
    "    \n",
    "    list_and = list()\n",
    "    for x in df_read_copy['Term']:\n",
    "            \n",
    "        if i == 'and':\n",
    "            if (indent[count-1] == df_read_copy['Term'].values[y]):\n",
    "                for v in df_read_copy['Term']:\n",
    "                    if(indent[count+1] == df_read_copy['Term'].values[n]):\n",
    "                        print(indent[count-1] + ' '+ i + ' ' + v)\n",
    "                        #print(df_read_copy['Documents'].values[y])\n",
    "                        #print(df_read_copy['Documents'].values[n])\n",
    "                        b = len(df_read_copy['Documents'].values[y])/7\n",
    "                        c = len(df_read_copy['Documents'].values[n])/7\n",
    "                        k = df_read_copy['Documents'].values[n][2:5]\n",
    "                        l = df_read_copy['Documents'].values[n][9:12]\n",
    "                        o = 2\n",
    "                        j = 5\n",
    "                        list_and = df_read_copy['Documents'].values[y][o:j]\n",
    "                        print('eh')\n",
    "                        print(\"['\"+ str(list_and) +\"']\")\n",
    "                        for m in range(max(int(b),int(c))):\n",
    "                            \n",
    "                            if(df_read_copy['Documents'].values[y][o:j] == df_read_copy['Documents'].values[n][o:j]):\n",
    "                                o+=7\n",
    "                                j+=7\n",
    "                            \n",
    "                                \n",
    "                    n+=1\n",
    "            checker=False\n",
    "        \n",
    "        elif i == 'or':\n",
    "            if (indent[count-1] == df_read_copy['Term'].values[y]):\n",
    "                for v in df_read_copy['Term']:\n",
    "                    if(indent[count+1] == df_read_copy['Term'].values[n]):\n",
    "                        print(indent[count-1] + ' '+ i + ' ' + v + '\\n')\n",
    "                        print(indent[count-1])\n",
    "                        print(df_read_copy['Documents'].values[y])\n",
    "                        print(v)\n",
    "                        print(df_read_copy['Documents'].values[n]) \n",
    "                    n+=1\n",
    "            checker=False\n",
    "                    \n",
    "        y+=1\n",
    "    count+=1\n",
    "    if len(indent)!=1:\n",
    "        if indent[z] == indent[z-1]:\n",
    "            break\n",
    "            \n",
    "if checker==True:\n",
    "    for i in indent:\n",
    "        y = 0\n",
    "        for x in df_read_copy['Term']:\n",
    "            if (i == df_read_copy['Term'].values[y]):\n",
    "                print(i)\n",
    "                print(df_read_copy['Documents'].values[y])\n",
    "            y+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
