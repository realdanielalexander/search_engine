{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import ast\n",
    "from itertools import islice\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Download Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load File</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "try:\n",
    "    filename = os.listdir('Data')[115]\n",
    "    f = open('Data/' + filename, 'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Case Folding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<date> 9-mar-1987 05:03:09.75</date>\n",
      "<title>bank of france sets money market tender</title>\n",
      "<body>the bank of france said it invited offers\n",
      "of first category paper today for a money market intervention\n",
      "tender.\n",
      "    money market dealers said conditions seemed right for the\n",
      "bank to cut its intervention rate at the tender by a quarter\n",
      "percentage point to 7-3/4 pct from eight, reflecting an easing\n",
      "in call money rate last week, and the french franc's steadiness\n",
      "on foreign exchange markets since the february 22 currency\n",
      "stabilisation accord here by the group of five and canada.\n",
      "    intervention rate was last raised to eight pct from 7-1/4\n",
      "on january 2. call money today was quoted at 7-11/16 7-3/4 pct.\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " 'date',\n",
       " '>',\n",
       " '9-mar-1987',\n",
       " '05:03:09.75',\n",
       " '<',\n",
       " '/date',\n",
       " '>',\n",
       " '<',\n",
       " 'title',\n",
       " '>',\n",
       " 'bank',\n",
       " 'of',\n",
       " 'france',\n",
       " 'sets',\n",
       " 'money',\n",
       " 'market',\n",
       " 'tender',\n",
       " '<',\n",
       " '/title',\n",
       " '>',\n",
       " '<',\n",
       " 'body',\n",
       " '>',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'of',\n",
       " 'france',\n",
       " 'said',\n",
       " 'it',\n",
       " 'invited',\n",
       " 'offers',\n",
       " 'of',\n",
       " 'first',\n",
       " 'category',\n",
       " 'paper',\n",
       " 'today',\n",
       " 'for',\n",
       " 'a',\n",
       " 'money',\n",
       " 'market',\n",
       " 'intervention',\n",
       " 'tender',\n",
       " '.',\n",
       " 'money',\n",
       " 'market',\n",
       " 'dealers',\n",
       " 'said',\n",
       " 'conditions',\n",
       " 'seemed',\n",
       " 'right',\n",
       " 'for',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'to',\n",
       " 'cut',\n",
       " 'its',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'at',\n",
       " 'the',\n",
       " 'tender',\n",
       " 'by',\n",
       " 'a',\n",
       " 'quarter',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'to',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " 'from',\n",
       " 'eight',\n",
       " ',',\n",
       " 'reflecting',\n",
       " 'an',\n",
       " 'easing',\n",
       " 'in',\n",
       " 'call',\n",
       " 'money',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'week',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'french',\n",
       " 'franc',\n",
       " \"'s\",\n",
       " 'steadiness',\n",
       " 'on',\n",
       " 'foreign',\n",
       " 'exchange',\n",
       " 'markets',\n",
       " 'since',\n",
       " 'the',\n",
       " 'february',\n",
       " '22',\n",
       " 'currency',\n",
       " 'stabilisation',\n",
       " 'accord',\n",
       " 'here',\n",
       " 'by',\n",
       " 'the',\n",
       " 'group',\n",
       " 'of',\n",
       " 'five',\n",
       " 'and',\n",
       " 'canada',\n",
       " '.',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'was',\n",
       " 'last',\n",
       " 'raised',\n",
       " 'to',\n",
       " 'eight',\n",
       " 'pct',\n",
       " 'from',\n",
       " '7-1/4',\n",
       " 'on',\n",
       " 'january',\n",
       " '2.',\n",
       " 'call',\n",
       " 'money',\n",
       " 'today',\n",
       " 'was',\n",
       " 'quoted',\n",
       " 'at',\n",
       " '7-11/16',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " '.',\n",
       " '<',\n",
       " '/body',\n",
       " '>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tokenisasi String + Regex</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<date>', '9-mar-1987', '05:03:09.75', '</date>', '<title>', 'bank', 'of', 'france', 'sets', 'money', 'market', 'tender', '</title>', '<body>', 'the', 'bank', 'of', 'france', 'said', 'it', 'invited', 'offers', 'of', 'first', 'category', 'paper', 'today', 'for', 'a', 'money', 'market', 'intervention', 'tender', 'money', 'market', 'dealers', 'said', 'conditions', 'seemed', 'right', 'for', 'the', 'bank', 'to', 'cut', 'its', 'intervention', 'rate', 'at', 'the', 'tender', 'by', 'a', 'quarter', 'percentage', 'point', 'to', '7-3/4', 'pct', 'from', 'eight', 'reflecting', 'an', 'easing', 'in', 'call', 'money', 'rate', 'last', 'week', 'and', 'the', 'french', 'franc', 'steadiness', 'on', 'foreign', 'exchange', 'markets', 'since', 'the', 'february', '22', 'currency', 'stabilisation', 'accord', 'here', 'by', 'the', 'group', 'of', 'five', 'and', 'canada', 'intervention', 'rate', 'was', 'last', 'raised', 'to', 'eight', 'pct', 'from', '7-1/4', 'on', 'january', '2', 'call', 'money', 'today', 'was', 'quoted', 'at', '7-11/16', '7-3/4', 'pct', '</body>']\n"
     ]
    }
   ],
   "source": [
    "# testing = \"Harga mangga per kg adalah 20.500.\"\n",
    "tokens = word_tokenize(text)\n",
    "# print(tokens[:5])\n",
    "# print(' '.join(tokens))\n",
    "check = ''\n",
    "def join_tags(tokens):\n",
    "    for i in enumerate(tokens):\n",
    "\n",
    "        index = i[0]\n",
    "        y = i[1]\n",
    "        width = len(y)\n",
    "\n",
    "\n",
    "        if y[(width-1):width] is '.':\n",
    "            tokens[index] = y[0:(width-1)]\n",
    "        \n",
    "#         if tokens[index][0:1] is '-' or tokens[index][1:2] is '-':\n",
    "#             tokens[index] = ''\n",
    "        \n",
    "        if tokens[index][-2:-1] is \"'\":\n",
    "            tokens[index] = tokens[index][0:-2]\n",
    "        \n",
    "        if  tokens[index][:1] is \"'\" :\n",
    "            tokens[index] = tokens[index][1:]\n",
    "        \n",
    "        if tokens[index] is \"s\" or tokens[index] is \"re\":\n",
    "            tokens[index-1] = tokens[index-1]\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if tokens[index] is '<' and tokens[index+2] is '>':\n",
    "            tokens[index+2] = '<'+ tokens[index+1]+'>'\n",
    "            tokens[index] =''\n",
    "            tokens[index+1] = ''\n",
    "            \n",
    "        if tokens[index] is '&' and tokens[index+2] is ';':\n",
    "            tokens[index+2] = ''\n",
    "            tokens[index] = ''\n",
    "            tokens[index+1] = ''\n",
    "            \n",
    "        if tokens[index] is '(' or tokens[index] is ')':\n",
    "            tokens[index] = ''\n",
    "            \n",
    "        if tokens[index][0:1] is ':':\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        if tokens[index][0:1] is '.' and tokens[index][1:2] is '.':\n",
    "            tokens[index] = ''\n",
    "        \n",
    "        \n",
    "    tokens_clean = [x for x in tokens if x != '' and x not in \".,!?'\" and x not in '<>']\n",
    "        \n",
    "    return tokens_clean\n",
    "\n",
    "tokens_clean = join_tags(tokens)\n",
    "print(tokens_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stop Words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<date>', '9-mar-1987', '05:03:09.75', '</date>', '<title>', 'bank', 'france', 'sets', 'money', 'market', 'tender', '</title>', '<body>', 'bank', 'france', 'said', 'invited', 'offers', 'first', 'category', 'paper', 'today', 'money', 'market', 'intervention', 'tender', 'money', 'market', 'dealers', 'said', 'conditions', 'seemed', 'right', 'bank', 'cut', 'intervention', 'rate', 'tender', 'quarter', 'percentage', 'point', '7-3/4', 'pct', 'eight', 'reflecting', 'easing', 'call', 'money', 'rate', 'last', 'week', 'french', 'franc', 'steadiness', 'foreign', 'exchange', 'markets', 'since', 'february', '22', 'currency', 'stabilisation', 'accord', 'group', 'five', 'canada', 'intervention', 'rate', 'last', 'raised', 'eight', 'pct', '7-1/4', 'january', '2', 'call', 'money', 'today', 'quoted', '7-11/16', '7-3/4', 'pct', '</body>']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [w for w in tokens_clean if not w in stop_words]\n",
    "print(filtered_words[:len(filtered_words)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stemming</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<date>', '9-mar-1987', '05:03:09.75', '</date>', '<title>', 'bank', 'franc', 'set', 'money', 'market', 'tender', '</title>', '<body>', 'bank', 'franc', 'said', 'invit', 'offer', 'first', 'categori', 'paper', 'today', 'money', 'market', 'intervent', 'tender', 'money', 'market', 'dealer', 'said', 'condit', 'seem', 'right', 'bank', 'cut', 'intervent', 'rate', 'tender', 'quarter', 'percentag', 'point', '7-3/4', 'pct', 'eight', 'reflect', 'eas', 'call', 'money', 'rate', 'last', 'week', 'french', 'franc', 'steadi', 'foreign', 'exchang', 'market', 'sinc', 'februari', '22', 'currenc', 'stabilis', 'accord', 'group', 'five', 'canada', 'intervent', 'rate', 'last', 'rais', 'eight', 'pct', '7-1/4', 'januari', '2', 'call', 'money', 'today', 'quot', '7-11/16', '7-3/4', 'pct', '</body>']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lemmatizing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam proses lematisasi, fungsi lemmatize pada NLTK membutuhkan tambahan parameter berupa POS (Part of Speech), yaitu konteks jenis kata, apakah kata berupa adjective, noun, verb, atau adverb. Maka dari itu, perlu dibuat suatu fungsi yang dapat mengembalikan objek POS dari library WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<date>',\n",
       " '9-mar-1987',\n",
       " '05:03:09.75',\n",
       " '</date>',\n",
       " '<title>',\n",
       " 'bank',\n",
       " 'france',\n",
       " 'set',\n",
       " 'money',\n",
       " 'market',\n",
       " 'tender',\n",
       " '</title>',\n",
       " '<body>',\n",
       " 'bank',\n",
       " 'france',\n",
       " 'say',\n",
       " 'invite',\n",
       " 'offer',\n",
       " 'first',\n",
       " 'category',\n",
       " 'paper',\n",
       " 'today',\n",
       " 'money',\n",
       " 'market',\n",
       " 'intervention',\n",
       " 'tender',\n",
       " 'money',\n",
       " 'market',\n",
       " 'dealer',\n",
       " 'say',\n",
       " 'condition',\n",
       " 'seem',\n",
       " 'right',\n",
       " 'bank',\n",
       " 'cut',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'tender',\n",
       " 'quarter',\n",
       " 'percentage',\n",
       " 'point',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " 'eight',\n",
       " 'reflect',\n",
       " 'ease',\n",
       " 'call',\n",
       " 'money',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'week',\n",
       " 'french',\n",
       " 'franc',\n",
       " 'steadiness',\n",
       " 'foreign',\n",
       " 'exchange',\n",
       " 'market',\n",
       " 'since',\n",
       " 'february',\n",
       " '22',\n",
       " 'currency',\n",
       " 'stabilisation',\n",
       " 'accord',\n",
       " 'group',\n",
       " 'five',\n",
       " 'canada',\n",
       " 'intervention',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'raise',\n",
       " 'eight',\n",
       " 'pct',\n",
       " '7-1/4',\n",
       " 'january',\n",
       " '2',\n",
       " 'call',\n",
       " 'money',\n",
       " 'today',\n",
       " 'quote',\n",
       " '7-11/16',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " '</body>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = list()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in filtered_words]\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stemming and Lemmatization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<date>',\n",
       " '9-mar-1987',\n",
       " '05:03:09.75',\n",
       " '</date>',\n",
       " '<title>',\n",
       " 'bank',\n",
       " 'franc',\n",
       " 'set',\n",
       " 'money',\n",
       " 'market',\n",
       " 'tender',\n",
       " '</title>',\n",
       " '<body>',\n",
       " 'bank',\n",
       " 'franc',\n",
       " 'say',\n",
       " 'invit',\n",
       " 'offer',\n",
       " 'first',\n",
       " 'categori',\n",
       " 'paper',\n",
       " 'today',\n",
       " 'money',\n",
       " 'market',\n",
       " 'intervent',\n",
       " 'tender',\n",
       " 'money',\n",
       " 'market',\n",
       " 'dealer',\n",
       " 'say',\n",
       " 'condit',\n",
       " 'seem',\n",
       " 'right',\n",
       " 'bank',\n",
       " 'cut',\n",
       " 'intervent',\n",
       " 'rate',\n",
       " 'tender',\n",
       " 'quarter',\n",
       " 'percentag',\n",
       " 'point',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " 'eight',\n",
       " 'reflect',\n",
       " 'ea',\n",
       " 'call',\n",
       " 'money',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'week',\n",
       " 'french',\n",
       " 'franc',\n",
       " 'steadi',\n",
       " 'foreign',\n",
       " 'exchang',\n",
       " 'market',\n",
       " 'sinc',\n",
       " 'februari',\n",
       " '22',\n",
       " 'currenc',\n",
       " 'stabilis',\n",
       " 'accord',\n",
       " 'group',\n",
       " 'five',\n",
       " 'canada',\n",
       " 'intervent',\n",
       " 'rate',\n",
       " 'last',\n",
       " 'rais',\n",
       " 'eight',\n",
       " 'pct',\n",
       " '7-1/4',\n",
       " 'januari',\n",
       " '2',\n",
       " 'call',\n",
       " 'money',\n",
       " 'today',\n",
       " 'quot',\n",
       " '7-11/16',\n",
       " '7-3/4',\n",
       " 'pct',\n",
       " '</body>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in stemmed_words]\n",
    "stemmed_lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabel Perbandingan Token</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di bawah ini ditampilkan tabel perbandingan dari token sebelum dan sesudah dilakukan dua pendekatan, yaitu stemming dan lematisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered</th>\n",
       "      <th>Stemmed</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Stemmed and Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;date&gt;</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9-mar-1987</td>\n",
       "      <td>9-mar-1987</td>\n",
       "      <td>9-mar-1987</td>\n",
       "      <td>9-mar-1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05:03:09.75</td>\n",
       "      <td>05:03:09.75</td>\n",
       "      <td>05:03:09.75</td>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;title&gt;</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>france</td>\n",
       "      <td>franc</td>\n",
       "      <td>france</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sets</td>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tender</td>\n",
       "      <td>tender</td>\n",
       "      <td>tender</td>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;body&gt;</td>\n",
       "      <td>&lt;body&gt;</td>\n",
       "      <td>&lt;body&gt;</td>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>france</td>\n",
       "      <td>franc</td>\n",
       "      <td>france</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>invited</td>\n",
       "      <td>invit</td>\n",
       "      <td>invite</td>\n",
       "      <td>invit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>offers</td>\n",
       "      <td>offer</td>\n",
       "      <td>offer</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>category</td>\n",
       "      <td>categori</td>\n",
       "      <td>category</td>\n",
       "      <td>categori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>paper</td>\n",
       "      <td>paper</td>\n",
       "      <td>paper</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>intervention</td>\n",
       "      <td>intervent</td>\n",
       "      <td>intervention</td>\n",
       "      <td>intervent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tender</td>\n",
       "      <td>tender</td>\n",
       "      <td>tender</td>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dealers</td>\n",
       "      <td>dealer</td>\n",
       "      <td>dealer</td>\n",
       "      <td>dealer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>steadiness</td>\n",
       "      <td>steadi</td>\n",
       "      <td>steadiness</td>\n",
       "      <td>steadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>foreign</td>\n",
       "      <td>foreign</td>\n",
       "      <td>foreign</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>exchange</td>\n",
       "      <td>exchang</td>\n",
       "      <td>exchange</td>\n",
       "      <td>exchang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>markets</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>since</td>\n",
       "      <td>sinc</td>\n",
       "      <td>since</td>\n",
       "      <td>sinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>february</td>\n",
       "      <td>februari</td>\n",
       "      <td>february</td>\n",
       "      <td>februari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>currency</td>\n",
       "      <td>currenc</td>\n",
       "      <td>currency</td>\n",
       "      <td>currenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>stabilisation</td>\n",
       "      <td>stabilis</td>\n",
       "      <td>stabilisation</td>\n",
       "      <td>stabilis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>accord</td>\n",
       "      <td>accord</td>\n",
       "      <td>accord</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>group</td>\n",
       "      <td>group</td>\n",
       "      <td>group</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>intervention</td>\n",
       "      <td>intervent</td>\n",
       "      <td>intervention</td>\n",
       "      <td>intervent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rate</td>\n",
       "      <td>rate</td>\n",
       "      <td>rate</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>last</td>\n",
       "      <td>last</td>\n",
       "      <td>last</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>raised</td>\n",
       "      <td>rais</td>\n",
       "      <td>raise</td>\n",
       "      <td>rais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>eight</td>\n",
       "      <td>eight</td>\n",
       "      <td>eight</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7-1/4</td>\n",
       "      <td>7-1/4</td>\n",
       "      <td>7-1/4</td>\n",
       "      <td>7-1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>january</td>\n",
       "      <td>januari</td>\n",
       "      <td>january</td>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>call</td>\n",
       "      <td>call</td>\n",
       "      <td>call</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>quoted</td>\n",
       "      <td>quot</td>\n",
       "      <td>quote</td>\n",
       "      <td>quot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7-11/16</td>\n",
       "      <td>7-11/16</td>\n",
       "      <td>7-11/16</td>\n",
       "      <td>7-11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>7-3/4</td>\n",
       "      <td>7-3/4</td>\n",
       "      <td>7-3/4</td>\n",
       "      <td>7-3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filtered      Stemmed     Lemmatized Stemmed and Lemmatized\n",
       "0          <date>       <date>         <date>                 <date>\n",
       "1      9-mar-1987   9-mar-1987     9-mar-1987             9-mar-1987\n",
       "2     05:03:09.75  05:03:09.75    05:03:09.75            05:03:09.75\n",
       "3         </date>      </date>        </date>                </date>\n",
       "4         <title>      <title>        <title>                <title>\n",
       "5            bank         bank           bank                   bank\n",
       "6          france        franc         france                  franc\n",
       "7            sets          set            set                    set\n",
       "8           money        money          money                  money\n",
       "9          market       market         market                 market\n",
       "10         tender       tender         tender                 tender\n",
       "11       </title>     </title>       </title>               </title>\n",
       "12         <body>       <body>         <body>                 <body>\n",
       "13           bank         bank           bank                   bank\n",
       "14         france        franc         france                  franc\n",
       "15           said         said            say                    say\n",
       "16        invited        invit         invite                  invit\n",
       "17         offers        offer          offer                  offer\n",
       "18          first        first          first                  first\n",
       "19       category     categori       category               categori\n",
       "20          paper        paper          paper                  paper\n",
       "21          today        today          today                  today\n",
       "22          money        money          money                  money\n",
       "23         market       market         market                 market\n",
       "24   intervention    intervent   intervention              intervent\n",
       "25         tender       tender         tender                 tender\n",
       "26          money        money          money                  money\n",
       "27         market       market         market                 market\n",
       "28        dealers       dealer         dealer                 dealer\n",
       "29           said         said            say                    say\n",
       "..            ...          ...            ...                    ...\n",
       "53     steadiness       steadi     steadiness                 steadi\n",
       "54        foreign      foreign        foreign                foreign\n",
       "55       exchange      exchang       exchange                exchang\n",
       "56        markets       market         market                 market\n",
       "57          since         sinc          since                   sinc\n",
       "58       february     februari       february               februari\n",
       "59             22           22             22                     22\n",
       "60       currency      currenc       currency                currenc\n",
       "61  stabilisation     stabilis  stabilisation               stabilis\n",
       "62         accord       accord         accord                 accord\n",
       "63          group        group          group                  group\n",
       "64           five         five           five                   five\n",
       "65         canada       canada         canada                 canada\n",
       "66   intervention    intervent   intervention              intervent\n",
       "67           rate         rate           rate                   rate\n",
       "68           last         last           last                   last\n",
       "69         raised         rais          raise                   rais\n",
       "70          eight        eight          eight                  eight\n",
       "71            pct          pct            pct                    pct\n",
       "72          7-1/4        7-1/4          7-1/4                  7-1/4\n",
       "73        january      januari        january                januari\n",
       "74              2            2              2                      2\n",
       "75           call         call           call                   call\n",
       "76          money        money          money                  money\n",
       "77          today        today          today                  today\n",
       "78         quoted         quot          quote                   quot\n",
       "79        7-11/16      7-11/16        7-11/16                7-11/16\n",
       "80          7-3/4        7-3/4          7-3/4                  7-3/4\n",
       "81            pct          pct            pct                    pct\n",
       "82        </body>      </body>        </body>                </body>\n",
       "\n",
       "[83 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "df_raw['Token'] = tokens_clean\n",
    "df['Filtered'] = filtered_words\n",
    "df['Stemmed'] = stemmed_words\n",
    "df['Lemmatized'] = lemmatized_words\n",
    "df['Stemmed and Lemmatized'] = stemmed_lemmatized_words\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabel Perbandingan Term</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term adalah token yang unik, di mana setiap term hanya muncul satu kali. Kami menggunakan fungsi set() untuk membuat setiap kata muncul hanya satu kali. Berbeda dengan token yang dapat muncul beberapa kali, term menggabungkan beberapa kata dasar dengan infleksi yang berbeda, sehingga tidak dapat ditampilkan secara side-by-side karena jumlahnya tidak sesuai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_set = list(set(tokens_clean))\n",
    "\n",
    "aa = filtered_words\n",
    "aaa = stemmed_words\n",
    "aaaa = lemmatized_words\n",
    "filtered_set = sorted(list(set(filtered_words)))\n",
    "stemmed_set = sorted(list(set(stemmed_words)))\n",
    "lemmatized_set = sorted(list(set(lemmatized_words)))\n",
    "\n",
    "df_filtered_set = pd.DataFrame(filtered_set,columns=['Filtered'])\n",
    "df_stemmed_set = pd.DataFrame(stemmed_set,columns=['Stemmed'])\n",
    "df_lemmatized_set = pd.DataFrame(lemmatized_set,columns=['Lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7-3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9-mar-1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>easing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>invited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>offers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>quoted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>raised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>reflecting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>seemed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>stabilisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>steadiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filtered\n",
       "0     05:03:09.75\n",
       "1               2\n",
       "2              22\n",
       "3           7-1/4\n",
       "4         7-11/16\n",
       "5           7-3/4\n",
       "6      9-mar-1987\n",
       "7         </body>\n",
       "8         </date>\n",
       "9        </title>\n",
       "10         <body>\n",
       "11         <date>\n",
       "12        <title>\n",
       "13         accord\n",
       "14           bank\n",
       "15           call\n",
       "16         canada\n",
       "17       category\n",
       "18     conditions\n",
       "19       currency\n",
       "20            cut\n",
       "21        dealers\n",
       "22         easing\n",
       "23          eight\n",
       "24       exchange\n",
       "25       february\n",
       "26          first\n",
       "27           five\n",
       "28        foreign\n",
       "29          franc\n",
       "30         france\n",
       "31         french\n",
       "32          group\n",
       "33   intervention\n",
       "34        invited\n",
       "35        january\n",
       "36           last\n",
       "37         market\n",
       "38        markets\n",
       "39          money\n",
       "40         offers\n",
       "41          paper\n",
       "42            pct\n",
       "43     percentage\n",
       "44          point\n",
       "45        quarter\n",
       "46         quoted\n",
       "47         raised\n",
       "48           rate\n",
       "49     reflecting\n",
       "50          right\n",
       "51           said\n",
       "52         seemed\n",
       "53           sets\n",
       "54          since\n",
       "55  stabilisation\n",
       "56     steadiness\n",
       "57         tender\n",
       "58          today\n",
       "59           week"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7-3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9-mar-1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>categori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>condit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>currenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dealer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>exchang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>februari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>intervent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>invit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>percentag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>quot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>rais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>reflect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>seem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>stabilis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>steadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Stemmed\n",
       "0   05:03:09.75\n",
       "1             2\n",
       "2            22\n",
       "3         7-1/4\n",
       "4       7-11/16\n",
       "5         7-3/4\n",
       "6    9-mar-1987\n",
       "7       </body>\n",
       "8       </date>\n",
       "9      </title>\n",
       "10       <body>\n",
       "11       <date>\n",
       "12      <title>\n",
       "13       accord\n",
       "14         bank\n",
       "15         call\n",
       "16       canada\n",
       "17     categori\n",
       "18       condit\n",
       "19      currenc\n",
       "20          cut\n",
       "21       dealer\n",
       "22          eas\n",
       "23        eight\n",
       "24      exchang\n",
       "25     februari\n",
       "26        first\n",
       "27         five\n",
       "28      foreign\n",
       "29        franc\n",
       "30       french\n",
       "31        group\n",
       "32    intervent\n",
       "33        invit\n",
       "34      januari\n",
       "35         last\n",
       "36       market\n",
       "37        money\n",
       "38        offer\n",
       "39        paper\n",
       "40          pct\n",
       "41    percentag\n",
       "42        point\n",
       "43      quarter\n",
       "44         quot\n",
       "45         rais\n",
       "46         rate\n",
       "47      reflect\n",
       "48        right\n",
       "49         said\n",
       "50         seem\n",
       "51          set\n",
       "52         sinc\n",
       "53     stabilis\n",
       "54       steadi\n",
       "55       tender\n",
       "56        today\n",
       "57         week"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stemmed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05:03:09.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-1/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7-3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9-mar-1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;/body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;/date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;/title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;body&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;date&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;title&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dealer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>invite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>quote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>reflect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>seem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>stabilisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>steadiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lemmatized\n",
       "0     05:03:09.75\n",
       "1               2\n",
       "2              22\n",
       "3           7-1/4\n",
       "4         7-11/16\n",
       "5           7-3/4\n",
       "6      9-mar-1987\n",
       "7         </body>\n",
       "8         </date>\n",
       "9        </title>\n",
       "10         <body>\n",
       "11         <date>\n",
       "12        <title>\n",
       "13         accord\n",
       "14           bank\n",
       "15           call\n",
       "16         canada\n",
       "17       category\n",
       "18      condition\n",
       "19       currency\n",
       "20            cut\n",
       "21         dealer\n",
       "22           ease\n",
       "23          eight\n",
       "24       exchange\n",
       "25       february\n",
       "26          first\n",
       "27           five\n",
       "28        foreign\n",
       "29          franc\n",
       "30         france\n",
       "31         french\n",
       "32          group\n",
       "33   intervention\n",
       "34         invite\n",
       "35        january\n",
       "36           last\n",
       "37         market\n",
       "38          money\n",
       "39          offer\n",
       "40          paper\n",
       "41            pct\n",
       "42     percentage\n",
       "43          point\n",
       "44        quarter\n",
       "45          quote\n",
       "46          raise\n",
       "47           rate\n",
       "48        reflect\n",
       "49          right\n",
       "50            say\n",
       "51           seem\n",
       "52            set\n",
       "53          since\n",
       "54  stabilisation\n",
       "55     steadiness\n",
       "56         tender\n",
       "57          today\n",
       "58           week"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmatized_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Penggabungan token menjadi teks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teks diproses dengan Stemming</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<date> 9-mar-1987 05:03:09.75 </date> <title> bank franc set money market tender </title> <body> bank franc said invit offer first categori paper today money market intervent tender money market dealer said condit seem right bank cut intervent rate tender quarter percentag point 7-3/4 pct eight reflect eas call money rate last week french franc steadi foreign exchang market sinc februari 22 currenc stabilis accord group five canada intervent rate last rais eight pct 7-1/4 januari 2 call money today quot 7-11/16 7-3/4 pct </body>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_text = ' '.join(stemmed_words)\n",
    "stemmed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teks diproses dengan Lematisasi</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<date> 9-mar-1987 05:03:09.75 </date> <title> bank france set money market tender </title> <body> bank france say invite offer first category paper today money market intervention tender money market dealer say condition seem right bank cut intervention rate tender quarter percentage point 7-3/4 pct eight reflect ease call money rate last week french franc steadiness foreign exchange market since february 22 currency stabilisation accord group five canada intervention rate last raise eight pct 7-1/4 january 2 call money today quote 7-11/16 7-3/4 pct </body>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text = ' '.join(lemmatized_words)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mempermudah pekerjaan, kami membuat fungsi - fungsi di atas menjadi satu fungsi yaitu preprocess. Fungsi ini akan menerima parameter teks dan return teks dengan dua pendekatan, yaitu stemming dan lematisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_process):\n",
    "    text_process = text_process.lower()\n",
    "    tokens = word_tokenize(text_process)\n",
    "    tokens_clean = join_tags(tokens)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [w for w in tokens_clean if not w in stop_words]\n",
    "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in stemmed_words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    #clean_text = lemmatized_text\n",
    "    clean_text = lemmatized_text\n",
    "    clean_words = sorted(list([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in stemmed_words]))\n",
    "    clean_text = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root>' + clean_text + '</root>'\n",
    "    return clean_text, clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_term_doc = dict()\n",
    "# clean_words_list = list()\n",
    "# raw_words_list = list()\n",
    "# dict_term_doc_final = dict()\n",
    "# data = dict()\n",
    "# key = list()\n",
    "# value = list()\n",
    "for i in os.listdir('Data'):\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Data/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        clean_text = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root>' + text + '</root>'\n",
    "        target = 'XML/' + filename[:-3] +'xml'\n",
    "        new_file = open(target, 'w+')\n",
    "        new_file.write(clean_text)\n",
    "        new_file.close()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "# for i in sorted(dict_term_doc.keys()):\n",
    "#     dict_term_doc_final[i] = dict_term_doc[i]\n",
    "    \n",
    "# df_term_doc = pd.DataFrame(dict_term_doc_final.items(), columns = ['Term', 'Documents'])\n",
    "\n",
    "# df_term_doc.to_csv('Konstruksi Indeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america', 'north', 'oil', 'standard']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'standard oil north america'\n",
    "clean_query_text, clean_query_words = preprocess(query)\n",
    "clean_query_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GAES INI FUNGSI LANGUAGE MODEL YAA MAAF BELUM RAPIH TAPI JALAN KOK HEHE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "{'001': 331, '002': 60, '003': 48, '004': 285, '005': 136, '006': 179}\n",
      "[('002', 0.00185679012345679), ('001', 0.00146484375), ('003', 0.00146484375), ('004', 0.00146484375), ('005', 0.00146484375)]\n"
     ]
    }
   ],
   "source": [
    "dict_term_doc = dict()\n",
    "clean_words_list = list()\n",
    "raw_words_list = list()\n",
    "dict_term_doc_final = dict()\n",
    "data = dict()\n",
    "key = list()\n",
    "value = list()\n",
    "doc_freqs = dict()\n",
    "\n",
    "query = 'standard oil north america'\n",
    "clean_query_text, clean_query_words = preprocess(query)\n",
    "lambd = 1/4\n",
    "limit = 5\n",
    "result_dict = list()\n",
    "\n",
    "global_freq = 0\n",
    "\n",
    "for index, i in enumerate(os.listdir('Data')):\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Data/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        clean_text, clean_words = preprocess(text)\n",
    "        clean_words_list.extend(clean_words)\n",
    "        \n",
    "#         print(clean_words)\n",
    "        doc_freq = 0\n",
    "        for w in clean_words:\n",
    "            doc_freq+=1\n",
    "            doc_freqs[filename[4:7]] = doc_freq\n",
    "            if w not in dict_term_doc:\n",
    "                dict_term_doc[w] = [1, {filename[4:7]: 1}]\n",
    "            else:\n",
    "                if filename[4:7] in dict_term_doc[w][1]:\n",
    "                    dict_term_doc[w][1][filename[4:7]]+=1\n",
    "                else:\n",
    "                    dict_term_doc[w][1][filename[4:7]]=1\n",
    "                dict_term_doc[w][0]+=1\n",
    "        print(index)\n",
    "        if index == limit:\n",
    "            break\n",
    "#         target = 'Clean/' + filename[:-3] +'xml'\n",
    "#         new_file = open(target, 'w+')\n",
    "#         new_file.write(clean_text)\n",
    "#         new_file.close()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "print(doc_freqs)\n",
    "df_doc_freqs = pd.DataFrame(doc_freqs.items(), columns = ['Document', 'Frequency'])\n",
    "df_doc_freqs.to_csv('Document Frequencies.csv')\n",
    "\n",
    "for i in sorted(dict_term_doc.keys()):\n",
    "    dict_term_doc_final[i] = dict_term_doc[i]\n",
    "\n",
    "\n",
    "    \n",
    "df_term_doc = pd.DataFrame(dict_term_doc_final.items(), columns = ['Term', 'Documents'])\n",
    "\n",
    "df_term_doc.to_csv('Frequencies.csv')\n",
    "\n",
    "df = pd.read_csv('Frequencies.csv')\n",
    "df_doc_freq = pd.read_csv('Document Frequencies.csv')\n",
    "\n",
    "global_freq = 0\n",
    "for i in islice(df.iterrows(), limit):\n",
    "    documents = i[1][2].strip('][').replace(\"'\", \"\").split(', ')\n",
    "    try:\n",
    "        global_freq+=int(documents[0])\n",
    "    except:\n",
    "        print('noo')\n",
    "\n",
    "for i in islice(df_doc_freq.iterrows(), limit):\n",
    "    local_freq = i[1]['Frequency']\n",
    "    doc_number = i[1]['Document']\n",
    "    doc_number = str(doc_number).zfill(3)\n",
    "    result = 1\n",
    "    for j in query.split():\n",
    "        entries = df.loc[df['Term'] == j]['Documents'].values[0]\n",
    "        entries = entries.split(', ',1)\n",
    "        entries[0] = entries[0].replace(\"[\", \"\")\n",
    "        entries[1] = entries[1].replace(']', '')\n",
    "        entries[1] = ast.literal_eval(entries[1])\n",
    "        if doc_number in entries[1].keys():\n",
    "            prob = (float(entries[1][doc_number])/float(local_freq)*lambd) + (float(entries[0])/float(global_freq)*(1-lambd))\n",
    "        else:\n",
    "            prob = (float(entries[0])/float(global_freq)*(1-lambd))\n",
    "        result *= prob\n",
    "    result_dict.append((doc_number, result))\n",
    "result_sorted = sorted(result_dict, key=lambda x: x[1], reverse=True)\n",
    "print(result_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'001\": 331, \"'002\": 60, \"'003\": 48, \"'004\": 285, \"'005\": 136, \"'006\": 179, \"'007\": 60, \"'008\": 72, \"'009\": 51, \"'010\": 149, \"'011\": 59, \"'012\": 97, \"'013\": 105, \"'014\": 52, \"'015\": 73, \"'016\": 285, \"'017\": 50, \"'018\": 174, \"'019\": 67, \"'020\": 69, \"'021\": 57, \"'022\": 34, \"'023\": 150, \"'024\": 75, \"'025\": 47, \"'026\": 184, \"'027\": 68, \"'028\": 434, \"'029\": 78, \"'030\": 22, \"'031\": 24, \"'032\": 127, \"'033\": 45, \"'034\": 49, \"'035\": 45, \"'036\": 29, \"'037\": 72, \"'038\": 59, \"'039\": 75, \"'040\": 75, \"'041\": 85, \"'042\": 72, \"'043\": 66, \"'044\": 66, \"'045\": 251, \"'046\": 85, \"'047\": 129, \"'048\": 41, \"'049\": 72, \"'050\": 39, \"'051\": 81, \"'052\": 31, \"'053\": 27, \"'054\": 338, \"'055\": 127, \"'056\": 121, \"'057\": 72, \"'058\": 65, \"'059\": 171, \"'060\": 128, \"'061\": 190, \"'062\": 65, \"'063\": 68, \"'064\": 44, \"'065\": 53, \"'066\": 79, \"'067\": 42, \"'068\": 46, \"'069\": 81, \"'070\": 97, \"'071\": 28, \"'072\": 39, \"'073\": 33, \"'074\": 98, \"'075\": 61, \"'076\": 23, \"'077\": 23, \"'078\": 453, \"'079\": 69, \"'080\": 73, \"'081\": 76, \"'082\": 44, \"'083\": 80, \"'084\": 28, \"'085\": 26, \"'086\": 45, \"'087\": 55, \"'088\": 63, \"'089\": 44, \"'090\": 44, \"'091\": 58, \"'092\": 58, \"'093\": 73, \"'094\": 109, \"'095\": 172, \"'096\": 29, \"'097\": 289, \"'098\": 379, \"'099\": 76, \"'100\": 47, \"'101\": 65, \"'102\": 47, \"'103\": 65, \"'104\": 42, \"'105\": 77, \"'106\": 66, \"'107\": 213, \"'108\": 20, \"'109\": 84, \"'110\": 72, \"'111\": 152, \"'112\": 58, \"'113\": 41, \"'114\": 94, \"'115\": 72, \"'116\": 83, \"'117\": 70, \"'118\": 56, \"'119\": 40, \"'120\": 75, \"'121\": 57, \"'122\": 178, \"'123\": 474, \"'124\": 133, \"'125\": 65, \"'126\": 80, \"'127\": 75, \"'128\": 89, \"'129\": 85, \"'130\": 60, \"'131\": 113, \"'132\": 137, \"'133\": 312, \"'134\": 179, \"'135\": 214, \"'136\": 179, \"'137\": 39, \"'138\": 143, \"'139\": 101, \"'140\": 134, \"'141\": 61, \"'142\": 125, \"'143\": 51, \"'144\": 23, \"'145\": 68, \"'146\": 40, \"'147\": 89, \"'148\": 87, \"'149\": 70, \"'150\": 178, \"'151\": 77, \"'152\": 70, \"'153\": 114, \"'154\": 190, \"'155\": 149, \"'156\": 70, \"'157\": 99, \"'158\": 145, \"'159\": 57, \"'160\": 63, \"'161\": 36, \"'162\": 132, \"'163\": 66, \"'164\": 49, \"'165\": 78, \"'166\": 28, \"'167\": 59, \"'168\": 121, \"'169\": 64, \"'170\": 41, \"'171\": 60, \"'172\": 84, \"'173\": 45, \"'174\": 92, \"'175\": 56, \"'176\": 81, \"'177\": 59, \"'178\": 74, \"'179\": 36, \"'180\": 110, \"'181\": 27, \"'182\": 35, \"'183\": 53, \"'184\": 69, \"'185\": 69, \"'186\": 40, \"'187\": 26, \"'188\": 73, \"'189\": 29, \"'190\": 48, \"'191\": 67, \"'192\": 75, \"'193\": 82, \"'194\": 321, \"'195\": 235, \"'196\": 140, \"'197\": 192, \"'198\": 76, \"'199\": 46, \"'200\": 150, \"'201\": 246, \"'202\": 140, \"'203\": 66, \"'204\": 136, \"'205\": 76, \"'206\": 68, \"'207\": 405, \"'208\": 374, \"'209\": 121, \"'210\": 142, \"'211\": 68, \"'212\": 77, \"'213\": 37, \"'214\": 39, \"'215\": 74, \"'216\": 39, \"'217\": 96, \"'218\": 143, \"'219\": 64, \"'220\": 30, \"'221\": 101, \"'222\": 63, \"'223\": 87, \"'224\": 53, \"'225\": 36, \"'226\": 66, \"'227\": 260, \"'228\": 74, \"'229\": 117, \"'230\": 156, \"'231\": 55, \"'232\": 37, \"'233\": 79, \"'234\": 152, \"'235\": 243, \"'236\": 67, \"'237\": 26, \"'238\": 57, \"'239\": 153, \"'240\": 33, \"'241\": 46, \"'242\": 110, \"'243\": 95, \"'244\": 30, \"'245\": 50, \"'246\": 172, \"'247\": 78, \"'248\": 110, \"'249\": 118, \"'250\": 70, \"'251\": 50, \"'252\": 38, \"'253\": 29, \"'254\": 345, \"'255\": 251, \"'256\": 144, \"'257\": 85, \"'258\": 78, \"'259\": 146, \"'260\": 67, \"'261\": 368, \"'262\": 371, \"'263\": 70, \"'264\": 164, \"'265\": 468, \"'266\": 144, \"'267\": 125, \"'268\": 301, \"'269\": 218, \"'270\": 76, \"'271\": 43, \"'272\": 147, \"'273\": 57, \"'274\": 22, \"'275\": 81, \"'276\": 157, \"'277\": 202, \"'278\": 48, \"'279\": 73, \"'280\": 51, \"'281\": 74, \"'282\": 78, \"'283\": 46, \"'284\": 193, \"'285\": 59, \"'286\": 39, \"'287\": 52, \"'288\": 71, \"'289\": 39, \"'290\": 55, \"'291\": 27, \"'292\": 283, \"'293\": 140, \"'294\": 41, \"'295\": 63, \"'296\": 47, \"'297\": 69, \"'298\": 68, \"'299\": 52, \"'300\": 28, \"'301\": 68, \"'302\": 146, \"'303\": 95, \"'304\": 107, \"'305\": 312, \"'306\": 83, \"'307\": 77, \"'308\": 59, \"'309\": 68, \"'310\": 68, \"'311\": 75, \"'312\": 63, \"'313\": 60, \"'314\": 341, \"'315\": 62, \"'316\": 144, \"'317\": 73, \"'318\": 138, \"'319\": 61, \"'320\": 127, \"'321\": 29, \"'322\": 201, \"'323\": 86, \"'324\": 62, \"'325\": 110, \"'326\": 52, \"'327\": 46, \"'328\": 68, \"'329\": 78, \"'330\": 89, \"'331\": 19, \"'332\": 70, \"'333\": 121, \"'334\": 63, \"'335\": 54, \"'336\": 154, \"'337\": 28, \"'338\": 57, \"'339\": 77, \"'340\": 384, \"'341\": 45, \"'342\": 82, \"'343\": 145, \"'344\": 53, \"'345\": 41, \"'346\": 41, \"'347\": 58, \"'348\": 299, \"'349\": 128, \"'350\": 74, \"'351\": 73, \"'352\": 42, \"'353\": 62, \"'354\": 65, \"'355\": 109, \"'356\": 47, \"'357\": 64, \"'358\": 79, \"'359\": 80, \"'360\": 37, \"'361\": 42, \"'362\": 36, \"'363\": 50, \"'364\": 67, \"'365\": 57, \"'366\": 54, \"'367\": 70, \"'368\": 40, \"'369\": 30, \"'370\": 71, \"'371\": 76, \"'372\": 194, \"'373\": 66, \"'374\": 63, \"'375\": 127, \"'376\": 489, \"'377\": 178, \"'378\": 60, \"'379\": 202, \"'380\": 73, \"'381\": 62, \"'382\": 77, \"'383\": 274, \"'384\": 27, \"'385\": 76, \"'386\": 91, \"'387\": 76, \"'388\": 69, \"'389\": 92, \"'390\": 49, \"'391\": 70, \"'392\": 127, \"'393\": 59, \"'394\": 52, \"'395\": 107, \"'396\": 61, \"'397\": 102, \"'398\": 20, \"'399\": 328, \"'400\": 62, \"'401\": 55, \"'402\": 124, \"'403\": 47, \"'404\": 97, \"'405\": 137, \"'406\": 80, \"'407\": 47, \"'408\": 90, \"'409\": 134, \"'410\": 81, \"'411\": 27, \"'412\": 55, \"'413\": 32, \"'414\": 27, \"'415\": 57, \"'416\": 39, \"'417\": 69, \"'418\": 71, \"'419\": 121, \"'420\": 43, \"'421\": 93, \"'422\": 228, \"'423\": 58, \"'424\": 51, \"'425\": 230, \"'426\": 66, \"'427\": 34, \"'428\": 108, \"'429\": 29, \"'430\": 43, \"'431\": 134, \"'432\": 72, \"'433\": 200, \"'434\": 140, \"'435\": 122, \"'436\": 152, \"'437\": 220, \"'438\": 132, \"'439\": 155, \"'440\": 49, \"'441\": 202, \"'442\": 47, \"'443\": 31, \"'444\": 77, \"'445\": 315, \"'446\": 73, \"'447\": 104, \"'448\": 462, \"'449\": 76, \"'450\": 46, \"'451\": 327, \"'452\": 33, \"'453\": 77, \"'454\": 214, \"'455\": 44, \"'456\": 40, \"'457\": 141, \"'458\": 77, \"'459\": 126, \"'460\": 43, \"'461\": 55, \"'462\": 90, \"'463\": 393, \"'464\": 50, \"'465\": 119, \"'466\": 129, \"'467\": 63, \"'468\": 34, \"'469\": 123, \"'470\": 84, \"'471\": 72, \"'472\": 69, \"'473\": 50, \"'474\": 81, \"'475\": 120, \"'476\": 73, \"'477\": 38, \"'478\": 50, \"'479\": 41, \"'480\": 29, \"'481\": 29, \"'482\": 138, \"'483\": 102, \"'484\": 124, \"'485\": 54, \"'486\": 47, \"'487\": 82, \"'488\": 108, \"'489\": 60, \"'490\": 56, \"'491\": 82, \"'492\": 195, \"'493\": 210, \"'494\": 321, \"'495\": 263, \"'496\": 306, \"'497\": 267, \"'498\": 208, \"'499\": 67, \"'500\": 49}\n"
     ]
    }
   ],
   "source": [
    "print(doc_freqs)\n",
    "df_doc_freqs = pd.DataFrame(doc_freqs.items(), columns = ['Document', 'Frequency'])\n",
    "df_doc_freqs.to_csv('Document Frequencies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('001', 331), ('002', 60), ('003', 48), ('004', 285), ('005', 136), ('006', 179), ('007', 60), ('008', 72), ('009', 51), ('010', 149), ('011', 59), ('012', 97), ('013', 105), ('014', 52), ('015', 73), ('016', 285), ('017', 50), ('018', 174), ('019', 67), ('020', 69), ('021', 57), ('022', 34), ('023', 150), ('024', 75), ('025', 47), ('026', 184), ('027', 68), ('028', 434), ('029', 78), ('030', 22), ('031', 24), ('032', 127), ('033', 45), ('034', 49), ('035', 45), ('036', 29), ('037', 72), ('038', 59), ('039', 75), ('040', 75), ('041', 85), ('042', 72), ('043', 66), ('044', 66), ('045', 251), ('046', 85), ('047', 129), ('048', 41), ('049', 72), ('050', 39), ('051', 81), ('052', 31), ('053', 27), ('054', 338), ('055', 127), ('056', 121), ('057', 72), ('058', 65), ('059', 171), ('060', 128), ('061', 190), ('062', 65), ('063', 68), ('064', 44), ('065', 53), ('066', 79), ('067', 42), ('068', 46), ('069', 81), ('070', 97), ('071', 28), ('072', 39), ('073', 33), ('074', 98), ('075', 61), ('076', 23), ('077', 23), ('078', 453), ('079', 69), ('080', 73), ('081', 76), ('082', 44), ('083', 80), ('084', 28), ('085', 26), ('086', 45), ('087', 55), ('088', 63), ('089', 44), ('090', 44), ('091', 58), ('092', 58), ('093', 73), ('094', 109), ('095', 172), ('096', 29), ('097', 289), ('098', 379), ('099', 76), ('100', 47), ('101', 65), ('102', 47), ('103', 65), ('104', 42), ('105', 77), ('106', 66), ('107', 213), ('108', 20), ('109', 84), ('110', 72), ('111', 152), ('112', 58), ('113', 41), ('114', 94), ('115', 72), ('116', 83), ('117', 70), ('118', 56), ('119', 40), ('120', 75), ('121', 57), ('122', 178), ('123', 474), ('124', 133), ('125', 65), ('126', 80), ('127', 75), ('128', 89), ('129', 85), ('130', 60), ('131', 113), ('132', 137), ('133', 312), ('134', 179), ('135', 214), ('136', 179), ('137', 39), ('138', 143), ('139', 101), ('140', 134), ('141', 61), ('142', 125), ('143', 51), ('144', 23), ('145', 68), ('146', 40), ('147', 89), ('148', 87), ('149', 70), ('150', 178), ('151', 77), ('152', 70), ('153', 114), ('154', 190), ('155', 149), ('156', 70), ('157', 99), ('158', 145), ('159', 57), ('160', 63), ('161', 36), ('162', 132), ('163', 66), ('164', 49), ('165', 78), ('166', 28), ('167', 59), ('168', 121), ('169', 64), ('170', 41), ('171', 60), ('172', 84), ('173', 45), ('174', 92), ('175', 56), ('176', 81), ('177', 59), ('178', 74), ('179', 36), ('180', 110), ('181', 27), ('182', 35), ('183', 53), ('184', 69), ('185', 69), ('186', 40), ('187', 26), ('188', 73), ('189', 29), ('190', 48), ('191', 67), ('192', 75), ('193', 82), ('194', 321), ('195', 235), ('196', 140), ('197', 192), ('198', 76), ('199', 46), ('200', 150), ('201', 246), ('202', 140), ('203', 66), ('204', 136), ('205', 76), ('206', 68), ('207', 405), ('208', 374), ('209', 121), ('210', 142), ('211', 68), ('212', 77), ('213', 37), ('214', 39), ('215', 74), ('216', 39), ('217', 96), ('218', 143), ('219', 64), ('220', 30), ('221', 101), ('222', 63), ('223', 87), ('224', 53), ('225', 36), ('226', 66), ('227', 260), ('228', 74), ('229', 117), ('230', 156), ('231', 55), ('232', 37), ('233', 79), ('234', 152), ('235', 243), ('236', 67), ('237', 26), ('238', 57), ('239', 153), ('240', 33), ('241', 46), ('242', 110), ('243', 95), ('244', 30), ('245', 50), ('246', 172), ('247', 78), ('248', 110), ('249', 118), ('250', 70), ('251', 50), ('252', 38), ('253', 29), ('254', 345), ('255', 251), ('256', 144), ('257', 85), ('258', 78), ('259', 146), ('260', 67), ('261', 368), ('262', 371), ('263', 70), ('264', 164), ('265', 468), ('266', 144), ('267', 125), ('268', 301), ('269', 218), ('270', 76), ('271', 43), ('272', 147), ('273', 57), ('274', 22), ('275', 81), ('276', 157), ('277', 202), ('278', 48), ('279', 73), ('280', 51), ('281', 74), ('282', 78), ('283', 46), ('284', 193), ('285', 59), ('286', 39), ('287', 52), ('288', 71), ('289', 39), ('290', 55), ('291', 27), ('292', 283), ('293', 140), ('294', 41), ('295', 63), ('296', 47), ('297', 69), ('298', 68), ('299', 52), ('300', 28), ('301', 68), ('302', 146), ('303', 95), ('304', 107), ('305', 312), ('306', 83), ('307', 77), ('308', 59), ('309', 68), ('310', 68), ('311', 75), ('312', 63), ('313', 60), ('314', 341), ('315', 62), ('316', 144), ('317', 73), ('318', 138), ('319', 61), ('320', 127), ('321', 29), ('322', 201), ('323', 86), ('324', 62), ('325', 110), ('326', 52), ('327', 46), ('328', 68), ('329', 78), ('330', 89), ('331', 19), ('332', 70), ('333', 121), ('334', 63), ('335', 54), ('336', 154), ('337', 28), ('338', 57), ('339', 77), ('340', 384), ('341', 45), ('342', 82), ('343', 145), ('344', 53), ('345', 41), ('346', 41), ('347', 58), ('348', 299), ('349', 128), ('350', 74), ('351', 73), ('352', 42), ('353', 62), ('354', 65), ('355', 109), ('356', 47), ('357', 64), ('358', 79), ('359', 80), ('360', 37), ('361', 42), ('362', 36), ('363', 50), ('364', 67), ('365', 57), ('366', 54), ('367', 70), ('368', 40), ('369', 30), ('370', 71), ('371', 76), ('372', 194), ('373', 66), ('374', 63), ('375', 127), ('376', 489), ('377', 178), ('378', 60), ('379', 202), ('380', 73), ('381', 62), ('382', 77), ('383', 274), ('384', 27), ('385', 76), ('386', 91), ('387', 76), ('388', 69), ('389', 92), ('390', 49), ('391', 70), ('392', 127), ('393', 59), ('394', 52), ('395', 107), ('396', 61), ('397', 102), ('398', 20), ('399', 328), ('400', 62), ('401', 55), ('402', 124), ('403', 47), ('404', 97), ('405', 137), ('406', 80), ('407', 47), ('408', 90), ('409', 134), ('410', 81), ('411', 27), ('412', 55), ('413', 32), ('414', 27), ('415', 57), ('416', 39), ('417', 69), ('418', 71), ('419', 121), ('420', 43), ('421', 93), ('422', 228), ('423', 58), ('424', 51), ('425', 230), ('426', 66), ('427', 34), ('428', 108), ('429', 29), ('430', 43), ('431', 134), ('432', 72), ('433', 200), ('434', 140), ('435', 122), ('436', 152), ('437', 220), ('438', 132), ('439', 155), ('440', 49), ('441', 202), ('442', 47), ('443', 31), ('444', 77), ('445', 315), ('446', 73), ('447', 104), ('448', 462), ('449', 76), ('450', 46), ('451', 327), ('452', 33), ('453', 77), ('454', 214), ('455', 44), ('456', 40), ('457', 141), ('458', 77), ('459', 126), ('460', 43), ('461', 55), ('462', 90), ('463', 393), ('464', 50), ('465', 119), ('466', 129), ('467', 63), ('468', 34), ('469', 123), ('470', 84), ('471', 72), ('472', 69), ('473', 50), ('474', 81), ('475', 120), ('476', 73), ('477', 38), ('478', 50), ('479', 41), ('480', 29), ('481', 29), ('482', 138), ('483', 102), ('484', 124), ('485', 54), ('486', 47), ('487', 82), ('488', 108), ('489', 60), ('490', 56), ('491', 82), ('492', 195), ('493', 210), ('494', 321), ('495', 263), ('496', 306), ('497', 267), ('498', 208), ('499', 67), ('500', 49)])\n"
     ]
    }
   ],
   "source": [
    "print(doc_freqs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Frequency Words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = dict()\n",
    "key_words = []\n",
    "\n",
    "for i in os.listdir('Clean'):\n",
    "    try:\n",
    "        filename = i\n",
    "        f = open('Clean/' + filename, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        words = text.split()\n",
    "        for w in words: \n",
    "            freq_dict[w] = freq_dict.get(w,0) + 1\n",
    "            key_words.append(freq_dict)\n",
    "        print(freq_dict)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# def words_frequency(text):\n",
    "#     freq_dict = dict()\n",
    "#     print(text)\n",
    "#     for wrd in text:\n",
    "#         print (wrd)\n",
    "#         wds = wrd.split()\n",
    "#         for w in wds: \n",
    "#             freq_dict[w] = freq_dict.get(w,0) + 1\n",
    "#     return freq_dict\n",
    "\n",
    "# frequency_words = words_frequency(stemmed_lemmatized_words)\n",
    "# frequency_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_freq = pd.DataFrame()\n",
    "\n",
    "# df_freq['Words'] = freq_dict.keys()\n",
    "# df_freq['Total Frequency'] = freq_dict.values()\n",
    "\n",
    "# df_freq.to_csv(\"Frequency.csv\")\n",
    "\n",
    "# df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08:13:36.29',\n",
       " '1',\n",
       " '9-mar-1987',\n",
       " '</body>',\n",
       " '</date>',\n",
       " '</title>',\n",
       " '<body>',\n",
       " '<date>',\n",
       " '<title>',\n",
       " 'action',\n",
       " 'addit',\n",
       " 'african',\n",
       " 'african',\n",
       " 'african',\n",
       " 'allow',\n",
       " 'announc',\n",
       " 'anti-apartheid',\n",
       " 'appli',\n",
       " 'bill',\n",
       " 'clarif',\n",
       " 'comprehens',\n",
       " 'congress',\n",
       " 'congress',\n",
       " 'countri',\n",
       " 'decis',\n",
       " 'depart',\n",
       " 'fall',\n",
       " 'fall',\n",
       " 'felt',\n",
       " 'friday',\n",
       " 'good',\n",
       " 'hurt',\n",
       " 'import',\n",
       " 'import',\n",
       " 'import',\n",
       " 'import',\n",
       " 'industri',\n",
       " 'intend',\n",
       " 'juli',\n",
       " 'last',\n",
       " 'last',\n",
       " 'late',\n",
       " 'law',\n",
       " 'ore',\n",
       " 'ore',\n",
       " 'organ',\n",
       " 'oxid',\n",
       " 'oxid',\n",
       " 'pas',\n",
       " 'pas',\n",
       " 'pend',\n",
       " 'permit',\n",
       " 'permit',\n",
       " 'presid',\n",
       " 'process',\n",
       " 're-export',\n",
       " 'reagan',\n",
       " 'repair',\n",
       " 's.a',\n",
       " 'sanction',\n",
       " 'sanction',\n",
       " 'say',\n",
       " 'say',\n",
       " 'say',\n",
       " 'servic',\n",
       " 'south',\n",
       " 'south',\n",
       " 'south',\n",
       " 'state-control',\n",
       " 'take',\n",
       " 'temporari',\n",
       " 'temporarili',\n",
       " 'temporarili',\n",
       " 'third',\n",
       " 'treasuri',\n",
       " 'treasuri',\n",
       " 'treasuri',\n",
       " 'u.',\n",
       " 'u.',\n",
       " 'u.',\n",
       " 'u.s.-mad',\n",
       " 'uranium',\n",
       " 'uranium',\n",
       " 'uranium',\n",
       " 'veto',\n",
       " 'would',\n",
       " 'would']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Frequency Document</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read_freq = pd.read_csv('Konstruksi Indeks.csv')\n",
    "\n",
    "df_out = df_read_freq['Documents']\n",
    "total_freq = []\n",
    "\n",
    "for i in df_read_freq.iterrows():\n",
    "    l_freq = dict()\n",
    "    res = i.strip('][').replace(\"'\", \"\").split(', ')\n",
    "    for j in res:\n",
    "        if j in l_freq:\n",
    "            l_freq[j]+=1\n",
    "        else:\n",
    "            l_freq[j] = 1\n",
    "    \n",
    "    total_freq.append(l_freq)\n",
    "print(total_freq)\n",
    "df_freq_total = pd.DataFrame()\n",
    "df_freq_total['Total'] = total_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Search</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(\"Konstruksi Indeks.csv\")\n",
    "df_read_copy = df_read\n",
    "df_read_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"\")\n",
    "user_input = user_input.lower()\n",
    "user_input = word_tokenize(user_input)\n",
    "user_input = join_tags(user_input)\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indent = list()\n",
    "for i in user_input:\n",
    "    indent.append(i)\n",
    "    \n",
    "print(indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "checker = True\n",
    "for i in indent:\n",
    "    save = ''\n",
    "    n = 0\n",
    "    y = 0\n",
    "    z = 1\n",
    "    \n",
    "    list_and = list()\n",
    "    for x in df_read_copy['Term']:\n",
    "            \n",
    "        if i == 'and':\n",
    "            if (indent[count-1] == df_read_copy['Term'].values[y]):\n",
    "                for v in df_read_copy['Term']:\n",
    "                    if(indent[count+1] == df_read_copy['Term'].values[n]):\n",
    "                        print(indent[count-1] + ' '+ i + ' ' + v)\n",
    "                        #print(df_read_copy['Documents'].values[y])\n",
    "                        #print(df_read_copy['Documents'].values[n])\n",
    "                        b = len(df_read_copy['Documents'].values[y])/7\n",
    "                        c = len(df_read_copy['Documents'].values[n])/7\n",
    "                        k = df_read_copy['Documents'].values[n][2:5]\n",
    "                        l = df_read_copy['Documents'].values[n][9:12]\n",
    "                        o = 2\n",
    "                        j = 5\n",
    "                        list_and = df_read_copy['Documents'].values[y][o:j]\n",
    "                        print('eh')\n",
    "                        print(\"['\"+ str(list_and) +\"']\")\n",
    "                        for m in range(max(int(b),int(c))):\n",
    "                            \n",
    "                            if(df_read_copy['Documents'].values[y][o:j] == df_read_copy['Documents'].values[n][o:j]):\n",
    "                                o+=7\n",
    "                                j+=7\n",
    "                            \n",
    "                                \n",
    "                    n+=1\n",
    "            checker=False\n",
    "        \n",
    "        elif i == 'or':\n",
    "            if (indent[count-1] == df_read_copy['Term'].values[y]):\n",
    "                for v in df_read_copy['Term']:\n",
    "                    if(indent[count+1] == df_read_copy['Term'].values[n]):\n",
    "                        print(indent[count-1] + ' '+ i + ' ' + v + '\\n')\n",
    "                        print(indent[count-1])\n",
    "                        print(df_read_copy['Documents'].values[y])\n",
    "                        print(v)\n",
    "                        print(df_read_copy['Documents'].values[n]) \n",
    "                    n+=1\n",
    "            checker=False\n",
    "                    \n",
    "        y+=1\n",
    "    count+=1\n",
    "    if len(indent)!=1:\n",
    "        if indent[z] == indent[z-1]:\n",
    "            break\n",
    "            \n",
    "if checker==True:\n",
    "    for i in indent:\n",
    "        y = 0\n",
    "        for x in df_read_copy['Term']:\n",
    "            if (i == df_read_copy['Term'].values[y]):\n",
    "                print(i)\n",
    "                print(df_read_copy['Documents'].values[y])\n",
    "            y+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
